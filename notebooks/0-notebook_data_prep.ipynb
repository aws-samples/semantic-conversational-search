{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Data preparation\n",
    "### This notebook is used to preprocess and clean the Movies Dataset used for the workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries\n",
    "The following cell installs required python libraries specified in the 'requirements.txt' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell installs the required libraries specified in the 'requirements.txt' file\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sourcing\n",
    "\n",
    "The dataset we're using for that example is \"The Movies Dataset\".\n",
    "It contains metadata on over 45,000 movies. 26 million ratings from over 270,000 users and can be downloaded here:\n",
    "https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
    "\n",
    "The dataset has a \"CC0: Public Domain\" license\n",
    "https://creativecommons.org/publicdomain/zero/1.0/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract the dataset\n",
    "\n",
    "IMPORTANT: Note that you will need to authenticate in kaggle to download the file manually. \n",
    "https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
    "\n",
    "\n",
    "Then, copy the downloaded zip into the \"dataset\" folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell sets options for displaying data frames in Pandas to show all rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets the path for the dataset folder and the ZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../dataset\"\n",
    "\n",
    "#check the name of the downloaded zip file i.e. archive.zip and update below line to reflect the correct zip file name\n",
    "filename = \"archive.zip\"\n",
    "zip_file = f'{dataset_path}/{filename}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code extracts the contents of the ZIP file into the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zip_file) as zf:\n",
    "   zf.extractall(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code reads the CSV files from the dataset folder into separate Pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open files as dataframes\n",
    "credits_df = pd.read_csv('../dataset/credits.csv')\n",
    "keywords_df = pd.read_csv('../dataset/keywords.csv')\n",
    "links_small_df = pd.read_csv('../dataset/links_small.csv')\n",
    "links_df = pd.read_csv('../dataset/links.csv')\n",
    "movies_metadata_df = pd.read_csv('../dataset/movies_metadata.csv')\n",
    "ratings_small_df = pd.read_csv('../dataset/ratings_small.csv')\n",
    "ratings_df = pd.read_csv('../dataset/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code removes rows with missing values in the 'popularity' column and converts the data type of 'popularity' to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Popularity Columns (10) have mixed types, removing rows with popularity \n",
    "print(movies_metadata_df.shape)\n",
    "\n",
    "movies_metadata_df[\"popularity\"] = pd.to_numeric(movies_metadata_df[\"popularity\"], errors=\"coerce\")\n",
    "movies_metadata_df = movies_metadata_df.dropna(subset=[\"popularity\"])\n",
    "\n",
    "print(movies_metadata_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code displays the first two rows of the 'movies_metadata_df' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds a 'keywords' column to the 'movies_metadata_df' dataframe by extracting keywords from the 'keywords_df' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def add_keywords(id):\n",
    "    result = []\n",
    "    try:\n",
    "        keywords = keywords_df.loc[keywords_df['id'] == int(id), \"keywords\"].iloc[0]\n",
    "        list_of_dicts = ast.literal_eval(keywords)\n",
    "        for _dict in list_of_dicts:\n",
    "            result.append(_dict['name'])\n",
    "        return ','.join(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception:{e}\")\n",
    "        return \"\"\n",
    "\n",
    "#some rows have data quality issues, expect exceptions to be raised.\n",
    "movies_metadata_df['keywords'] = movies_metadata_df['id'].apply(lambda x: add_keywords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds a 'director' column to the 'movies_metadata_df' dataframe by extracting director information from the 'credits_df' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_director(id):\n",
    "    director = ''\n",
    "    try:\n",
    "        crew = credits_df.loc[credits_df['id'] == int(id), \"crew\"].iloc[0]\n",
    "        list_of_dicts = ast.literal_eval(crew)\n",
    "        for _dict in list_of_dicts:\n",
    "            if _dict['job'] == 'Director':\n",
    "                director = _dict['name']\n",
    "                break\n",
    "        return director\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return director\n",
    "    \n",
    "#some rows have data quality issues, expect exceptions to be raised.\n",
    "movies_metadata_df['director'] = movies_metadata_df['id'].apply(lambda x: add_director(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds an 'actors' column to the 'movies_metadata_df' dataframe by extracting the top 3 actors from the 'credits_df' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_actors(id):\n",
    "    actors = []\n",
    "    try:\n",
    "        cast = credits_df.loc[credits_df['id'] == int(id), \"cast\"].iloc[0]\n",
    "        list_of_dicts = ast.literal_eval(cast)\n",
    "        counter = 0\n",
    "        for _dict in list_of_dicts:\n",
    "            if _dict['order'] in [0,1,2]:\n",
    "                actors.append(_dict['name'])\n",
    "                counter += 1\n",
    "                if counter == 3:\n",
    "                    break\n",
    "        return \",\".join(actors)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "#some rows have data quality issues, expect exceptions to be raised.\n",
    "movies_metadata_df['actors'] = movies_metadata_df['id'].apply(lambda x: add_actors(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code rounds the 'popularity' column values to one decimal place and converts the data type to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#round value to first decimal\n",
    "def update_popularity(num):\n",
    "  try:\n",
    "    return round(num, 1)\n",
    "  except Exception as e:\n",
    "    return 0\n",
    "\n",
    "movies_metadata_df['popularity'] = movies_metadata_df['popularity'].apply(lambda x: update_popularity(x))\n",
    "\n",
    "#casting as integer\n",
    "movies_metadata_df[\"popularity\"] = movies_metadata_df[\"popularity\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds a 'popularity_bins' column to the 'movies_metadata_df' dataframe by binning the 'popularity' values into five categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df[\"popularity_bins\"] = pd.qcut(movies_metadata_df['popularity'], 5, labels=['Very Low', 'Low', 'Average', 'High', 'Very High'], duplicates='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds a 'vote_average_bins' column to the 'movies_metadata_df' dataframe by binning the 'vote_average' values into five categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df[\"vote_average_bins\"] = pd.qcut(movies_metadata_df['vote_average'], 5, labels=['Very Low', 'Low', 'Average', 'High', 'Very High'], duplicates='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code updates the 'genres' column in the 'movies_metadata_df' dataframe by extracting genre names from the JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_genre(json_genre):\n",
    "    genres = []\n",
    "    try:\n",
    "        list_of_dicts = ast.literal_eval(json_genre)\n",
    "        for _dict in list_of_dicts:\n",
    "            genres.append(_dict['name'])\n",
    "        return \",\".join(genres)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "movies_metadata_df['genres'] = movies_metadata_df['genres'].apply(lambda x: update_genre(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds a 'year' column to the 'movies_metadata_df' dataframe by extracting the year from the 'release_date' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_year(x):\n",
    "    try:\n",
    "        #expected format 1995-10-30\n",
    "        return x.split('-')[0]\n",
    "    except Exception as e:\n",
    "        return \"\"\n",
    "\n",
    "movies_metadata_df['year'] = movies_metadata_df['release_date'].apply(lambda x: create_year(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code displays the null count for each column in the 'movies_metadata_df' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in movies_metadata_df.columns:\n",
    "  null_count = movies_metadata_df[col].isnull().sum()\n",
    "  print(f\"Null count in {col}: {null_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code displays the column names of the 'movies_metadata_df' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code renames the 'id' and 'overview' columns, selects relevant columns, and creates two new dataframes: 'to_export_df_full' (containing all rows) and 'to_export_df_small' (containing the top 200 rows sorted by popularity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the id column to tmdb_id\n",
    "movies_metadata_df.rename(columns={'id': 'tmdb_id'}, inplace=True)\n",
    "\n",
    "#renaming the overview column to description\n",
    "movies_metadata_df.rename(columns={'overview': 'description'}, inplace=True)\n",
    "\n",
    "cols_selection = ['tmdb_id', 'original_language', 'original_title', 'description', 'genres', 'year', 'keywords', 'director', 'actors', 'popularity', 'popularity_bins',\n",
    "                  'vote_average', 'vote_average_bins']\n",
    "\n",
    "#full 45K dataset\n",
    "to_export_df_full = movies_metadata_df[cols_selection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code displays the first 10 rows of the 'to_export_df_small' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small version for workshop's purpose. we're selection the top 200 most popular.\n",
    "to_export_df_small = to_export_df_full.sort_values(by=['popularity'], ascending=[False])[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code displays the first 10 rows of the 'to_export_df_small' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export_df_small.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code exports the concise('to_export_df_small') and full('to_export_df_full') datasets as CSV files in the dataset folder.\n",
    "For the remaining part of this workshop, we will be working with the concise data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "to_export_df_small.to_csv('../dataset/movies_metadata_small.csv', index=False)\n",
    "to_export_df_full.to_csv('../dataset/movies_metadata_45K.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
